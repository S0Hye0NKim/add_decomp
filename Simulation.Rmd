---
title: "Simulation"
author: "Sohyeon Kim"
output: 
  github_document:
    pandoc_args: --webtex
header-includes:
  - \usepackage{kotex}
---


```{r warning = FALSE, message = FALSE}
library(tidyverse)
library(ggplot2)
library(splines)
library(Matrix)
library(pander)
library(gridExtra)
library(foreach)
library(doParallel)
library(Rcpp)
library(glmnet)
library(fda)

sourceCpp("functions/add_decomp_function.cpp")
source("https://raw.githubusercontent.com/S0Hye0NKim/add_decomp/master/functions/add_decomp_function.R")
```


# Case 1. 




$$\tilde{\textbf{x}}_i\overset{i.i.d}{\sim}N_p(0,\Sigma)\text{ with }\Sigma_{jk}=0.3^{|j-k|}$$

$$\epsilon_i^{(g)}(\tau)\sim N(0, \sigma_i^{(g)2})\text{ where }\sigma_i\overset{i.i.d}{\sim}U(0.3, 0.7)$$

## 0. Initial Setting


```{r}
set.seed(0)
n <- 400
m <- 10
p <- 30
b <- 21
num_rank <- 5
simul_times <- 100

sigma_mat <- matrix(nrow = p, ncol = p)
for(j in 1:p) {
  for(k in 1:p) {
    sigma_mat[j, k] <- 0.3^(abs(j-k))
  }
}

X_list <- list()
LR_mat_list <- list()
sp_mat_list <- list()
eps_list <- list()

for(simul in 1:simul_times) {
  X <- matrix(rnorm(n*p, mean = 0, sd = 1), nrow = n)
  X_list[[simul]] <- X %*% expm::sqrtm(sigma_mat) %>%
    cbind(rep(1, n), .)
  
  col_ind <- sample(1:m, size = m, replace = FALSE)
  row_ind <- sample(1:(p+1), size = m)
  sp_mat_list[[simul]] <- matrix(0, nrow = p+1, ncol = m)
  for(i in 1:m) {
    sp_mat_list[[simul]][row_ind[i], col_ind[i]] <- rnorm(1, mean = 5, sd = 0.1)
  }
  
  LR_mat <- matrix(rnorm((p+1)*m, mean = 1, sd = 0.1), ncol = m) # make low rank matrix using SVD
  SVD <- svd(LR_mat)
  D_mat <- diag(SVD$d)
  idx <- (num_rank+1):m
  D_mat[idx, idx] <- 0
  LR_mat_list[[simul]] <- SVD$u %*% D_mat %*% t(SVD$v)
  
  sigma <- runif(n,0.3,0.7)
  eps_list[[simul]] <- mvrnorm(n = m, mu = rep(0,n), Sigma = diag(sigma^2,n)) %>% t()
}

Y_list <- mapply(FUN = function(X, LR, SP, eps) X %*% (LR + SP) + eps, 
                 X_list, LR_mat_list, sp_mat_list, eps_list, SIMPLIFY = FALSE)



```

## 1. Basis Function.

```{r}
K <- 10
tau_seq <- seq(from = 0.4, to = 0.6, length.out = b)

knots_seq <- seq(min(tau_seq) - 0.02, max(tau_seq) + 0.02, length.out = K)
Phi <- fda::bsplineS(tau_seq, breaks= knots_seq, norder=2, nderiv=0, returnMatrix=FALSE)

V_list <- list()
for(simul in 1:simul_times) {
  V_list[[simul]] <- calc_V(X_list[[simul]], Phi)
}
```


## 2. algorithm


```{r}
add_decomp_r <- function(delta, lambda_1, lambda_2, tol_error, max_iter, X, Y, V, Phi, theta_0, alpha_0) {
  # delta = step size
  # lambda_1 = low rank penalty
  # lambda_2 = sparse penalty
  
  # initial value
  eta_old <- theta_0
  theta_old <- eta_old
  alpha_old <- alpha_0
  Z_old <- X %*% alpha_old
  e_old <- list()
  for(l in 1:b) {e_old[[l]] <- Y - Z_old - V[[l]] %*% eta_old}
  u_old <- list()
  for(l in 1:b) {u_old[[l]] <- matrix(0, nrow = n, ncol = m)}
  w_old <- matrix(0, nrow = (p+1)*K, ncol = m)
  
  iter_error <- matrix(ncol = 6, nrow = max_iter) %>%
    `colnames<-`(value = c("eta", "theta", "alpha", "e", "u", "w"))
  
  sum_V <- Reduce("+", V)
  VV_prod <- lapply(V, FUN = function(x) t(x) %*% x)   # V^TV
  sum_VV <- Reduce("+", VV_prod)
  
  for(iter in 1:max_iter) {
    # Process for eta
    eta_new <- matrix(nrow = (p+1)*K, ncol = m)
    Vu_prod <- mapply(function(x,y) t(x) %*% y, V, u_old, SIMPLIFY = FALSE)
    Ve_prod <- mapply(function(x,y) t(x) %*% y, V, e_old, SIMPLIFY = FALSE)
    eta_new <- (solve(sum_VV+diag(1, (p+1)*K))/delta) %*% (w_old + delta * theta_old + Reduce("+", Vu_prod)
                                                           + delta * t(sum_V) %*% (Y - Z_old)
                                                           - delta * Reduce("+", Ve_prod))
    
    # Process for theta
    theta_new <- matrix(nrow = (p+1)*K, ncol = m)
    for (g in 1:m) {
      for(j in 1:(p+1)) {
        eta_j_g <- eta_new[(K*(j-1) +1):(j*K), g]
        w_j_g <- w_old[(K*(j-1) +1):(j*K), g]
        r_j_g <- eta_j_g - (w_j_g/delta)
        norm <- (r_j_g^2) %>% sum %>% sqrt
        value <- 1 - (lambda_2/(delta *norm))
        if(value >= 0) {
          theta_new[(K*(j-1) +1):(j*K), g] <- value * r_j_g
        } else {theta_new[(K*(j-1) +1):(j*K), g] <- 0}
      }
    }
    
    # Process for Z=XA
    Y_list <- list()
    for(i in 1:l) {Y_list[[i]] <- Y}
    VH_list <- lapply(V, FUN = function(x) x %*% eta_new)
    obj_list <- mapply(function(Y, VH, E, U) Y - VH - E - U/delta, Y_list, VH_list, e_old, u_old, SIMPLIFY = FALSE)
    obj <- Reduce("+", obj_list)/b 
    SVD <- svd(obj)
    new_singular <- sapply(SVD$d - lambda_1/(delta*b), FUN = function(x) max(x, 0))
    Z_new <- SVD$u %*% diag(new_singular) %*% t(SVD$v)
    alpha_new <- solve(t(X) %*% X) %*% t(X) %*% Z_new
    
    # Process for e
    e_new <- list()
    for(l in 1:b){
      e_new[[l]] <- matrix(nrow = n, ncol = m)
      for(g in 1:m) {
        error <- Y[, g] - Z_new[, g] - V[[l]] %*% eta_new[, g]   #error = Y - XA - VH
        value <- error + u_old[[l]][, g]/delta
        e_new[[l]][, g] <- case_when(value > tau_seq[l]/(n*delta) ~ value - tau_seq[l]/(n*delta), 
                                     value < (tau_seq[l]-1)/(n*delta) ~ value - (tau_seq[l]-1)/(n*delta), 
                                     value >=(tau_seq[l]-1)/(n*delta) & value <= tau_seq[l]/(n*delta) ~ 0)
      }
    }
    
    # Process for multiplier u
    u_new <- list()
    for(l in 1:b) {
      u_new[[l]] <- u_old[[l]] + delta * (Y - Z_new - V[[l]] %*% eta_new - e_new[[l]])
    }
    
    # Process for multiplier w
    w_new <- w_old + delta * (theta_new - eta_new)
    
    # Update iteration error
    iter_error[iter, "eta"] <- Matrix::norm(eta_old - eta_new, type = "F")
    iter_error[iter, "theta"] <- Matrix::norm(theta_old - theta_new, type = "F")
    iter_error[iter, "alpha"] <- Matrix::norm(alpha_old - alpha_new, type = "F")
    e_diff <- mapply(FUN = function(old, new) old - new, e_old, e_new, SIMPLIFY = FALSE)  # sum of frobenius norm
    iter_error[iter, "e"] <- lapply(e_diff, FUN = function(x) Matrix::norm(x, type = "F")) %>% Reduce("+", .)
    u_diff <- mapply(FUN = function(old, new) old - new, u_old, u_new, SIMPLIFY = FALSE)
    iter_error[iter, "u"] <- lapply(u_diff, FUN = function(x) Matrix::norm(x, type = "F")) %>% Reduce("+", .)
    iter_error[iter, "w"] <- Matrix::norm(w_old - w_new, type = "F")
    
    if(sum(iter_error[iter, ]) < tol_error) break
    
    eta_old <- eta_new
    theta_old <- theta_new
    Z_old <- Z_new
    alpha_old <- alpha_new
    e_old <- e_new
    u_old <- u_new
    w_old <- w_new
  }
  
  return(list(eta = eta_new, 
              theta = theta_new, 
              alpha = alpha_new, 
              e = e_new, 
              u = u_new, 
              w = w_new, 
              iter_error = iter_error))
}
```



## 3. Simulation

```{r}
cores=detectCores()
cl <- makeCluster(cores[1]-2) #not to overload your computer
registerDoParallel(cl) # Ready to parallel

simulation <- foreach(simul = 1:simul_times) %dopar% {
  library(tidyverse)
  library(splines)
  library(Matrix)
  library(Rcpp)
  library(glmnet)
  library(fda)
  
  tau_seq <- seq(from = 0.4, to = 0.6, length.out = b)
  lasso_coef <- matrix(nrow = p+1, ncol = m)
  for(g in 1:m) {
    cv.lasso <- cv.glmnet(x = X_list[[simul]][, -1], y = Y_list[[simul]][, g], 
                          alpha = 1, type.measure = "mae")
    lasso_model <- glmnet(X_list[[simul]][, -1], Y_list[[simul]][, g], 
                          family = "gaussian", alpha = 1, lambda = cv.lasso$lambda.min)
    lasso_coef[, g] <- c(lasso_model$a0, as.vector(lasso_model$beta))
  }
  
  theta_init <- matrix(nrow = (p+1)*K, ncol = m)
  for(g in 1:m) {
    for(j in 0:p) {
      theta_init[((j*K)+1):((j+1)*K), g] <- lasso_coef[j+1, g]
    }
  }
  
  Y_modified <- Y_list[[simul]] - X_list[[simul]]%*%lasso_coef
  lin_model <- lm(Y_modified~., data = data.frame(X_list[[simul]][, -1]))
  alpha_init <- lin_model$coefficients
  
  result <- add_decomp_r(delta = 1, lambda_1 = 6, lambda_2 = 30, tol_error = 0.1,max_iter = 300,
                       X = X_list[[simul]], Y = Y_list[[simul]], V = V_list[[simul]], Phi = Phi, 
                     theta_0 = theta_init, alpha_0 = alpha_init)
  result
  
}



stopCluster(cl)
```


## 4. Evaluation.


### 4-1. Low rank matrix

```{r}
alpha_list <- lapply(simulation, FUN = function(x) x$alpha)

sapply(alpha_list, rankMatrix) %>% mean
```

```{r}
lapply(alpha_list, FUN= function(x) svd(x) %>% .$d) %>%
  sapply(FUN = function(x) sum(x[1:5])/sum(x)) %>% mean
```

### 4-2. Sparse matrix

```{r}
theta_list <- lapply(simulation, FUN = function(x) x$theta)

gamma_list <- lapply(theta_list, FUN = function(x) est_gamma(Phi, theta = x))
```


```{r message=FALSE}

sp_table <- list()
for(simul in 1:simul_times) {
  sp_table[[simul]] <- check_sp_table(true = sp_mat_list[[simul]], est = gamma_list[[simul]], 
                                      table = FALSE)
}


sp_table %>%
  bind_rows() %>%
  mutate(TP = TPR, TN = 1-FPR) %>%
  dplyr::select(TP, TN) %>%
  summarise(TP_mean = mean(TP), TP_sd = sd(TP), TN_mean = mean(TN), TN_sd = sd(TN))

```


### 4-3. SISE


$$\text{SISE} = \sum_{i=1}^n\sum_{g=1}^m\int_\Delta\big(\hat{Y}_i^{(g)}(\tau)-Y_i^{(g)}(\tau)\big)^2d\tau/m$$


```{r}
h <- tau_seq[2] - tau_seq[1]

SISE <- vector(mode = "numeric", length = simul_times)
for(simul in 1:simul_times) {
  alpha <- simulation[[simul]]$alpha
  theta <- simulation[[simul]]$theta
  gamma_tau <- est_gamma(Phi, theta)
  Y <- Y_list[[simul]]
  X <- X_list[[simul]]
  Y_hat <- lapply(gamma_tau, FUN = function(x) X %*% (x + alpha))
  SSE <- lapply(Y_hat, FUN = function(x) as.vector(x - Y)^2 %>% sum)
  SISE[simul] <- sapply(SSE[-1], FUN = function(x) (x/m)*h) %>% sum
  
}

c(mean(SISE), sd(SISE))
```

---

# Case 2. 

$$\epsilon_i^{(g)}(\tau)\sim\Phi(\tilde{x}_{i3})t_3$$


## 0. Initial Setting

```{r}
set.seed(0)
n <- 400
m <- 10
p <- 30
b <- 21
num_rank <- 5
simul_times <- 100

sigma_mat <- matrix(nrow = p, ncol = p)
for(j in 1:p) {
  for(k in 1:p) {
    sigma_mat[j, k] <- 0.3^(abs(j-k))
  }
}

X_list <- list()
LR_mat_list <- list()
sp_mat_list <- list()
eps_list <- list()

for(simul in 1:simul_times) {
  X <- matrix(rnorm(n*p, mean = 0, sd = 1), nrow = n)
  X_list[[simul]] <- X %*% expm::sqrtm(sigma_mat) %>%
    cbind(rep(1, n), .)
  
  col_ind <- sample(1:m, size = m, replace = FALSE)
  row_ind <- sample(1:(p+1), size = m)
  sp_mat_list[[simul]] <- matrix(0, nrow = p+1, ncol = m)
  for(i in 1:m) {
    sp_mat_list[[simul]][row_ind[i], col_ind[i]] <- rnorm(1, mean = 5, sd = 0.1)
  }
  
  LR_mat <- matrix(rnorm((p+1)*m, mean = 1, sd = 0.1), ncol = m) # make low rank matrix using SVD
  SVD <- svd(LR_mat)
  D_mat <- diag(SVD$d)
  idx <- (num_rank+1):m
  D_mat[idx, idx] <- 0
  LR_mat_list[[simul]] <- SVD$u %*% D_mat %*% t(SVD$v)
  
  eps_list[[simul]] <- matrix(nrow = n, ncol = m)
  for(i in 1:n) {
    for(j in 1:m) {
      x_i3 <- X_list[[simul]][i, 3]
      t_3 <- rt(1, df = 3)
      eps_list[[simul]][i, j] <- pnorm(x_i3)*t_3
    }
  }
}

Y_list <- mapply(FUN = function(X, LR, SP, eps) X %*% (LR + SP) + eps, 
                 X_list, LR_mat_list, sp_mat_list, eps_list, SIMPLIFY = FALSE)
```


## 1. Basis Function.

```{r}
K <- 10
tau_seq <- seq(from = 0.4, to = 0.6, length.out = b)

knots_seq <- seq(min(tau_seq) - 0.02, max(tau_seq) + 0.02, length.out = K)
Phi <- fda::bsplineS(tau_seq, breaks= knots_seq, norder=2, nderiv=0, returnMatrix=FALSE)

V_list <- list()
for(simul in 1:simul_times) {
  V_list[[simul]] <- calc_V(X_list[[simul]], Phi)
}
```


## 3. Simulation

```{r}
cores=detectCores()
cl <- makeCluster(cores[1]-2) #not to overload your computer
registerDoParallel(cl) # Ready to parallel

simulation <- foreach(simul = 1:simul_times) %dopar% {
  library(tidyverse)
  library(splines)
  library(Matrix)
  library(Rcpp)
  library(glmnet)
  library(fda)
  
  tau_seq <- seq(from = 0.4, to = 0.6, length.out = b)
  lasso_coef <- matrix(nrow = p+1, ncol = m)
  for(g in 1:m) {
    cv.lasso <- cv.glmnet(x = X_list[[simul]][, -1], y = Y_list[[simul]][, g], 
                          alpha = 1, type.measure = "mae")
    lasso_model <- glmnet(X_list[[simul]][, -1], Y_list[[simul]][, g], 
                          family = "gaussian", alpha = 1, lambda = cv.lasso$lambda.min)
    lasso_coef[, g] <- c(lasso_model$a0, as.vector(lasso_model$beta))
  }
  
  theta_init <- matrix(nrow = (p+1)*K, ncol = m)
  for(g in 1:m) {
    for(j in 0:p) {
      theta_init[((j*K)+1):((j+1)*K), g] <- lasso_coef[j+1, g]
    }
  }
  
  Y_modified <- Y_list[[simul]] - X_list[[simul]]%*%lasso_coef
  lin_model <- lm(Y_modified~., data = data.frame(X_list[[simul]][, -1]))
  alpha_init <- lin_model$coefficients
  
  result <- add_decomp_r(delta = 1, lambda_1 = 6, lambda_2 = 30, tol_error = 0.1,max_iter = 300,
                       X = X_list[[simul]], Y = Y_list[[simul]], V = V_list[[simul]], Phi = Phi, 
                     theta_0 = theta_init, alpha_0 = alpha_init)
  result
  
}



stopCluster(cl)
```


## 4. Evaluation.


### 4-1. Low rank matrix

```{r}
alpha_list <- lapply(simulation, FUN = function(x) x$alpha)

sapply(alpha_list, rankMatrix) %>% mean
```

```{r}
lapply(alpha_list, FUN= function(x) svd(x) %>% .$d) %>%
  sapply(FUN = function(x) sum(x[1:5])/sum(x)) %>% mean
```

### 4-2. Sparse matrix

```{r}
theta_list <- lapply(simulation, FUN = function(x) x$theta)

gamma_list <- lapply(theta_list, FUN = function(x) est_gamma(Phi, theta = x))
```


```{r message=FALSE}

sp_table <- list()
for(simul in 1:simul_times) {
  sp_table[[simul]] <- check_sp_table(true = sp_mat_list[[simul]], est = gamma_list[[simul]], 
                                      table = FALSE)
}


sp_table %>%
  bind_rows() %>%
  mutate(TP = TPR, TN = 1-FPR) %>%
  dplyr::select(TP, TN) %>%
  summarise(TP_mean = mean(TP), TP_sd = sd(TP), TN_mean = mean(TN), TN_sd = sd(TN))

```


### 4-3. SISE


$$\begin{aligned}\text{SISE}&=\sum_{i=1}^n\sum_{g=1}^m\int_\Delta\big(\hat{Y}_i^{(g)}(\tau)-Y_i^{(g)}(\tau)\big)^2d\tau/m\\&=\frac{h}{m}\sum_{\ell=1}^b\sum_{i=1}^n\sum_{g=1}^m\bigg(\hat{Y}_i^{(g)}(\tau_\ell)-Y_i^{(g)}(\tau_\ell)\bigg)\end{aligned}$$


```{r}
h <- tau_seq[2] - tau_seq[1]

SISE <- vector(mode = "numeric", length = simul_times)
for(simul in 1:simul_times) {
  alpha <- simulation[[simul]]$alpha
  theta <- simulation[[simul]]$theta
  gamma_tau <- est_gamma(Phi, theta)
  Y <- Y_list[[simul]]
  X <- X_list[[simul]]
  Y_hat <- lapply(gamma_tau, FUN = function(x) X %*% (x + alpha))
  SSE <- lapply(Y_hat, FUN = function(x) as.vector(x - Y)^2 %>% sum)
  SISE[simul] <- sapply(SSE[-1], FUN = function(x) (x/m)*h) %>% sum
  
}

c(mean(SISE), sd(SISE))
```


---

# Case 3. 

$$\epsilon_i^{(g)}(\tau)\sim\text{Laplace}(0, \sigma_i^{(g)}),\text{ where }\sigma_i^{(g)}\overset{i.i.d}{\sim}U(0.4, 0.7)$$


## 0. Initial Setting


```{r warning = FALSE}
set.seed(0)
n <- 400
m <- 10
p <- 30
b <- 21
num_rank <- 5
simul_times <- 100

sigma_mat <- matrix(nrow = p, ncol = p)
for(j in 1:p) {
  for(k in 1:p) {
    sigma_mat[j, k] <- 0.3^(abs(j-k))
  }
}

X_list <- list()
LR_mat_list <- list()
sp_mat_list <- list()
eps_list <- list()

for(simul in 1:simul_times) {
  X <- matrix(rnorm(n*p, mean = 0, sd = 1), nrow = n)
  X_list[[simul]] <- X %*% expm::sqrtm(sigma_mat) %>%
    cbind(rep(1, n), .)
  
  col_ind <- sample(1:m, size = m, replace = FALSE)
  row_ind <- sample(1:(p+1), size = m)
  sp_mat_list[[simul]] <- matrix(0, nrow = p+1, ncol = m)
  for(i in 1:m) {
    sp_mat_list[[simul]][row_ind[i], col_ind[i]] <- rnorm(1, mean = 5, sd = 0.1)
  }
  
  LR_mat <- matrix(rnorm((p+1)*m, mean = 1, sd = 0.1), ncol = m) # make low rank matrix using SVD
  SVD <- svd(LR_mat)
  D_mat <- diag(SVD$d)
  idx <- (num_rank+1):m
  D_mat[idx, idx] <- 0
  LR_mat_list[[simul]] <- SVD$u %*% D_mat %*% t(SVD$v)
  
  eps_list[[simul]] <- matrix(nrow = n, ncol = m)
  for(i in 1:n) {
    for(j in 1:m) {
      sigma <- runif(1, 0.4, 0.7)
      eps_list[[simul]][i, j] <- LaplacesDemon::rlaplace(1, location = 0, scale = sigma)
    }
  }
}

Y_list <- mapply(FUN = function(X, LR, SP, eps) X %*% (LR + SP) + eps, 
                 X_list, LR_mat_list, sp_mat_list, eps_list, SIMPLIFY = FALSE)



```

## 1. Basis Function.

```{r}
K <- 10
tau_seq <- seq(from = 0.4, to = 0.6, length.out = b)

knots_seq <- seq(min(tau_seq) - 0.02, max(tau_seq) + 0.02, length.out = K)
Phi <- fda::bsplineS(tau_seq, breaks= knots_seq, norder=2, nderiv=0, returnMatrix=FALSE)

V_list <- list()
for(simul in 1:simul_times) {
  V_list[[simul]] <- calc_V(X_list[[simul]], Phi)
}
```


## 3. Simulation

```{r}
cores=detectCores()
cl <- makeCluster(cores[1]-2) #not to overload your computer
registerDoParallel(cl) # Ready to parallel

simulation <- foreach(simul = 1:simul_times) %dopar% {
  library(tidyverse)
  library(splines)
  library(Matrix)
  library(Rcpp)
  library(glmnet)
  library(fda)
  
  tau_seq <- seq(from = 0.4, to = 0.6, length.out = b)
  lasso_coef <- matrix(nrow = p+1, ncol = m)
  for(g in 1:m) {
    cv.lasso <- cv.glmnet(x = X_list[[simul]][, -1], y = Y_list[[simul]][, g], 
                          alpha = 1, type.measure = "mae")
    lasso_model <- glmnet(X_list[[simul]][, -1], Y_list[[simul]][, g], 
                          family = "gaussian", alpha = 1, lambda = cv.lasso$lambda.min)
    lasso_coef[, g] <- c(lasso_model$a0, as.vector(lasso_model$beta))
  }
  
  theta_init <- matrix(nrow = (p+1)*K, ncol = m)
  for(g in 1:m) {
    for(j in 0:p) {
      theta_init[((j*K)+1):((j+1)*K), g] <- lasso_coef[j+1, g]
    }
  }
  
  Y_modified <- Y_list[[simul]] - X_list[[simul]]%*%lasso_coef
  lin_model <- lm(Y_modified~., data = data.frame(X_list[[simul]][, -1]))
  alpha_init <- lin_model$coefficients
  
  result <- add_decomp_r(delta = 1, lambda_1 = 6, lambda_2 = 30, tol_error = 0.1,max_iter = 300,
                       X = X_list[[simul]], Y = Y_list[[simul]], V = V_list[[simul]], Phi = Phi, 
                     theta_0 = theta_init, alpha_0 = alpha_init)
  result
  
}



stopCluster(cl)
```


## 4. Evaluation.


### 4-1. Low rank matrix

```{r}
alpha_list <- lapply(simulation, FUN = function(x) x$alpha)

sapply(alpha_list, rankMatrix) %>% mean
```

```{r}
lapply(alpha_list, FUN= function(x) svd(x) %>% .$d) %>%
  sapply(FUN = function(x) sum(x[1:5])/sum(x)) %>% mean
```

### 4-2. Sparse matrix

```{r}
theta_list <- lapply(simulation, FUN = function(x) x$theta)

gamma_list <- lapply(theta_list, FUN = function(x) est_gamma(Phi, theta = x))
```


```{r message=FALSE}

sp_table <- list()
for(simul in 1:simul_times) {
  sp_table[[simul]] <- check_sp_table(true = sp_mat_list[[simul]], est = gamma_list[[simul]], 
                                      table = FALSE)
}


sp_table %>%
  bind_rows() %>%
  mutate(TP = TPR, TN = 1-FPR) %>%
  dplyr::select(TP, TN) %>%
  summarise(TP_mean = mean(TP), TP_sd = sd(TP), TN_mean = mean(TN), TN_sd = sd(TN))

```


### 4-3. SISE


$$\text{SISE} = \sum_{i=1}^n\sum_{g=1}^m\int_\Delta\big(\hat{Y}_i^{(g)}(\tau)-Y_i^{(g)}(\tau)\big)^2d\tau/m$$


```{r}
h <- tau_seq[2] - tau_seq[1]

SISE <- vector(mode = "numeric", length = simul_times)
for(simul in 1:simul_times) {
  alpha <- simulation[[simul]]$alpha
  theta <- simulation[[simul]]$theta
  gamma_tau <- est_gamma(Phi, theta)
  Y <- Y_list[[simul]]
  X <- X_list[[simul]]
  Y_hat <- lapply(gamma_tau, FUN = function(x) X %*% (x + alpha))
  SSE <- lapply(Y_hat, FUN = function(x) as.vector(x - Y)^2 %>% sum)
  SISE[simul] <- sapply(SSE[-1], FUN = function(x) (x/m)*h) %>% sum
  
}

c(mean(SISE), sd(SISE))

```


# Solution Path

## 1. Data Generation

```{r}
set.seed(0)
n <- 400
m <- 10
p <- 30
b <- 21
num_rank <- 5

X <- matrix(rnorm(n*p, mean = 0, sd = 1), nrow = n) %>% cbind(1, .)   #add intercept term in X

col_ind <- sample(1:m, size = m, replace = FALSE)
row_ind <- sample(1:(p+1), size = m)
sp_mat <- matrix(0, nrow = p+1, ncol = m)
for(i in 1:m) {
  sp_mat[row_ind[i], col_ind[i]] <- rnorm(1, mean = 5, sd = 0.1)
}
num_zero <- which(sp_mat==0, arr.ind = TRUE) %>% nrow
num_nz <- (p+1)*m - num_zero

LR_mat <- matrix(rnorm((p+1)*m, mean = 1, sd = 0.1), ncol = m) # make low rank matrix using SVD
SVD <- svd(LR_mat)
D_mat <- diag(SVD$d)
idx <- (num_rank+1):m
D_mat[idx, idx] <- 0
LR_mat <- SVD$u %*% D_mat %*% t(SVD$v)          

true_B <- sp_mat + LR_mat            # B(tau) = sparse matrix + low rank matrix

eps <- matrix(rnorm(n*m, mean = 0, sd = 0.1), nrow = n)

Y <- X%*%true_B + eps
```

```{r}
K <- 10
tau_seq <- seq(from = 0.4, to = 0.6, length.out = b)

knots_seq <- seq(min(tau_seq) - 0.02, max(tau_seq) + 0.02, length.out = K)
Phi <- fda::bsplineS(tau_seq, breaks= knots_seq, norder=2, nderiv=0, returnMatrix=FALSE)

V <- calc_V(X, Phi)
```

## 2. Low rank

```{r}
cores=detectCores()
cl <- makeCluster(cores[1]-2) #not to overload your computer
registerDoParallel(cl) # Ready to parallel
lamb1_seq <- c(1:10, 15, 20, 30, 35)

simulation <- foreach(lambda_1 = lamb1_seq) %dopar% {
  library(tidyverse)
  library(splines)
  library(Matrix)
  library(Rcpp)
  library(glmnet)
  library(fda)
  
  tau_seq <- seq(from = 0.4, to = 0.6, length.out = b)
  lasso_coef <- matrix(nrow = p+1, ncol = m)
  for(g in 1:m) {
    cv.lasso <- cv.glmnet(x = X[, -1], y = Y[, g], 
                          alpha = 1, type.measure = "mae")
    lasso_model <- glmnet(X[, -1], Y[, g], 
                          family = "gaussian", alpha = 1, lambda = cv.lasso$lambda.min)
    lasso_coef[, g] <- c(lasso_model$a0, as.vector(lasso_model$beta))
  }
  
  theta_init <- matrix(nrow = (p+1)*K, ncol = m)
  for(g in 1:m) {
    for(j in 0:p) {
      theta_init[((j*K)+1):((j+1)*K), g] <- lasso_coef[j+1, g]
    }
  }
  
  Y_modified <- Y - X%*%lasso_coef
  lin_model <- lm(Y_modified~., data = data.frame(X[, -1]))
  alpha_init <- lin_model$coefficients
  
  result <- add_decomp_r(delta = 1, lambda_1 = lambda_1, lambda_2 = 20, tol_error = 0.1,max_iter = 300,
                       X = X, Y = Y, V = V, Phi = Phi, 
                     theta_0 = theta_init, alpha_0 = alpha_init)
  result
}



stopCluster(cl)
```



```{r}
rank <- simulation %>% sapply(FUN = function(x) x$alpha %>% rankMatrix %>% .[1])

data.frame(lambda_1 = lamb1_seq, rank = rank) %>%
  ggplot() +
  geom_line(aes(x = lambda_1, y = rank)) +
  labs(title = "Solution path for low rank matrix", 
       x = expression(lambda[1]))
```

## 3. Sparse matrix

```{r}
cores=detectCores()
cl <- makeCluster(cores[1]-2) #not to overload your computer
registerDoParallel(cl) # Ready to parallel
lamb2_seq <- c(seq(5, 60, by = 5), 70, 80, 90, 100)

simulation <- foreach(lambda_2 = lamb2_seq) %dopar% {
  library(tidyverse)
  library(splines)
  library(Matrix)
  library(Rcpp)
  library(glmnet)
  library(fda)
  
  tau_seq <- seq(from = 0.4, to = 0.6, length.out = b)
  lasso_coef <- matrix(nrow = p+1, ncol = m)
  for(g in 1:m) {
    cv.lasso <- cv.glmnet(x = X[, -1], y = Y[, g], 
                          alpha = 1, type.measure = "mae")
    lasso_model <- glmnet(X[, -1], Y[, g], 
                          family = "gaussian", alpha = 1, lambda = cv.lasso$lambda.min)
    lasso_coef[, g] <- c(lasso_model$a0, as.vector(lasso_model$beta))
  }
  
  theta_init <- matrix(nrow = (p+1)*K, ncol = m)
  for(g in 1:m) {
    for(j in 0:p) {
      theta_init[((j*K)+1):((j+1)*K), g] <- lasso_coef[j+1, g]
    }
  }
  
  Y_modified <- Y - X%*%lasso_coef
  lin_model <- lm(Y_modified~., data = data.frame(X[, -1]))
  alpha_init <- lin_model$coefficients
  
  result <- add_decomp_r(delta = 1, lambda_1 = 4, lambda_2 = lambda_2, tol_error = 0.1,max_iter = 300,
                       X = X, Y = Y, V = V, Phi = Phi, 
                     theta_0 = theta_init, alpha_0 = alpha_init)
  result
}



stopCluster(cl)
```


$$\int_\Delta\{\hat{\Gamma}(\tau)\}_{jg}d\tau=\sum_{\ell=1}^b\{\hat{\Gamma}(\tau)\}_{jg}\frac{\Delta}{(b-1)}$$

```{r}
h <- tau_seq[2] - tau_seq[1]
alpha_list <- lapply(simulation, FUN = function(x) x$alpha)
theta_list <- lapply(simulation, FUN = function(x) x$theta)
gamma_list <- lapply(theta_list, FUN = function(x) est_gamma(Phi, theta = x))

sum_gamma_list <- lapply(gamma_list, FUN = function(x) x[-1] %>% Reduce("+", .))
int_gamma <- sum_gamma_list %>% lapply(FUN = function(x) x*h)

int_gamma_tidy <- lapply(int_gamma, FUN = function(x) data.frame(col = rep(1:m, each = (p+1)), 
                                                          row = rep(1:(p+1), m),
                                                          value = as.vector(x))) %>%
  `names<-`(value = lamb2_seq) %>%
  bind_rows(.id = "lambda_2") %>% tbl_df %>%
  mutate(lambda_2 = as.numeric(lambda_2), row = as.character(row))

int_gamma_tidy %>%
  mutate(index = paste0("(", col, ",", row, ")")) %>%
  ggplot() +
  geom_line(aes(x = lambda_2, y = value, group = index)) +
  labs(title = "Solution path for sparse matrix", 
       x = expression(lambda[2]), 
       y = expression("integrate"~Gamma~"("~tau~")"))
```















