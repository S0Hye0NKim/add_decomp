---
title: "Simulation"
author: "Sohyeon Kim"
output: 
  github_document:
    pandoc_args: --webtex
header-includes:
  - \usepackage{kotex}
---


```{r warning = FALSE, message = FALSE}
library(tidyverse)
library(ggplot2)
library(splines)
library(Matrix)
library(pander)
library(gridExtra)
library(foreach)
library(doParallel)
library(Rcpp)
library(glmnet)
library(fda)

sourceCpp("functions/add_decomp_function.cpp")
source("https://raw.githubusercontent.com/S0Hye0NKim/add_decomp/master/functions/add_decomp_function.R")
```




# Case 1. 

$$\tilde{\textbf{x}}_i\overset{i.i.d}{\sim}N_{10}(0,\Sigma)\text{ with }\Sigma_{jk}=0.3^{|j-k|}$$

$$X_j=X_{j-10}-X_{j-9} \text{ for }j=11,\cdots,20$$

$$X_j=2X_{j-20}+X_{j-18}\text{ for }j=21,\cdots, 30$$

$$\epsilon_i^{(g)}(\tau)\sim N(0, \sigma_i^{(g)2})\text{ where }\sigma_i\overset{i.i.d}{\sim}U(0.3, 0.7)$$

## 0. Initial Setting


```{r}
set.seed(0)
n <- 400
m <- 10
p <- 30
b <- 15
num_rank <- 5
num_rank_X <- 10
simul_times <- 100

sigma_mat <- matrix(nrow = num_rank_X, ncol = num_rank_X)
for(j in 1:num_rank_X) {
  for(k in 1:num_rank_X) {
    sigma_mat[j, k] <- 0.3^(abs(j-k))
  }
}

X_list <- list()
LR_mat_list <- list()
sp_mat_list <- list()
eps_list <- list()

for(simul in 1:simul_times) {
  X <- matrix(rnorm(n*num_rank_X, mean = 0, sd = 1), nrow = n)
  X <- X %*% expm::sqrtm(sigma_mat)
  X <- cbind(X, X, X)
  for(j in 11:20) {
    X[, j] <- X[, j-10] + X[, j-9]
    X[, (j+10)] <- X[, j-10] + X[, j-8]
  }
  X_list[[simul]] <- X %>% cbind(rep(1, n), .)
  
  col_ind <- sample(1:m, size = m, replace = FALSE)
  row_ind <- sample(1:(p+1), size = m)
  sp_mat_list[[simul]] <- matrix(0, nrow = p+1, ncol = m)
  for(i in 1:m) {
    sp_mat_list[[simul]][row_ind[i], col_ind[i]] <- rnorm(1, mean = 5, sd = 0.1)
  }
  
  LR_mat <- matrix(rnorm((p+1)*m, mean = 0, sd = 1), ncol = m) # make low rank matrix using SVD
  SVD <- svd(LR_mat)
  D_mat <- diag(runif(num_rank, min = 2, max = 2.3) %>% sort(decreasing = TRUE), nrow = length(SVD$d))
  idx <- (num_rank+1):min(m, p)
  D_mat[idx, idx] <- 0
  LR_mat_list[[simul]] <- SVD$u %*% D_mat %*% t(SVD$v)
  
  sigma <- runif(n,0.3,0.7)
  eps_list[[simul]] <- MASS::mvrnorm(n = m, mu = rep(0,n), Sigma = diag(sigma^2,n)) %>% t()
}

Y_list <- mapply(FUN = function(X, LR, SP, eps) X %*% (LR + SP) + eps, 
                 X_list, LR_mat_list, sp_mat_list, eps_list, SIMPLIFY = FALSE)



```




---

# Case 2. 

$$B(\tau)=L+S(\tau)$$

$$y_{ik}=x_i^TB(\tau)^{(k)}+x_i^T\xi^{(k)}\epsilon_i\text{ where }\xi_3^{(k)}=1,\xi^{(k)}_j=0(j\ne3)$$


$$\epsilon\sim N(0, 1)$$


## 0. Initial Setting

```{r}
set.seed(0)
n <- 400
m <- 10
p <- 30
b <- 15
num_rank <- 5
num_rank_X <- 10

simul_times <- 100

sigma_mat <- matrix(nrow = num_rank_X, ncol = num_rank_X)
for(j in 1:num_rank_X) {
  for(k in 1:num_rank_X) {
    sigma_mat[j, k] <- 0.3^(abs(j-k))
  }
}

X_list <- list()
LR_mat_list <- list()
sp_mat_list <- list()
eps_list <- list()
xi_list <- list()

xi_mat <- matrix(0, nrow = (p+1), ncol = m) 
xi_mat[c(1,4), ] <- rep(1, m)

for(simul in 1:simul_times) {
  X <- matrix(rnorm(n*num_rank_X, mean = 0, sd = 1), nrow = n)
  X <- X %*% expm::sqrtm(sigma_mat)
  X <- cbind(X, X, X)
  for(j in 11:20) {
    X[, j] <- X[, j-10] + X[, j-9]
    X[, (j+10)] <- X[, j-10] + X[, j-8]
  }
  X_list[[simul]] <- X %>% cbind(rep(1, n), .)
  
  col_ind <- sample(1:m, size = m, replace = FALSE)
  row_ind <- sample(1:(p+1), size = m)
  sp_mat_list[[simul]] <- matrix(0, nrow = p+1, ncol = m)
  for(i in 1:m) {
    sp_mat_list[[simul]][row_ind[i], col_ind[i]] <- rnorm(1, mean = 5, sd = 0.1)
  }
  
  LR_mat <- matrix(rnorm((p+1)*m, mean = 0, sd = 1), ncol = m) # make low rank matrix using SVD
  SVD <- svd(LR_mat)
  D_mat <- diag(runif(num_rank, min = 2, max = 2.3) %>% sort(decreasing = TRUE), nrow = length(SVD$d))
  idx <- (num_rank+1):min(m, p)
  D_mat[idx, idx] <- 0
  LR_mat_list[[simul]] <- SVD$u %*% D_mat %*% t(SVD$v)
  
  eps_list[[simul]] <- matrix(rnorm(n*m), nrow = n, ncol = m)
  xi_list[[simul]] <- xi_mat
}



Y_list <- mapply(FUN = function(X, LR, SP, xi, eps) X %*% (LR + SP) + X %*% xi * eps, 
                 X_list, LR_mat_list, sp_mat_list, xi_list, eps_list, SIMPLIFY = FALSE)
```

---

# Case 3. 

 * Same as Example 1 except that $\epsilon_i^{(g)}\sim\text{Laplace}(0, \sigma_i)$, $\sigma_i \sim U(0.4, 0.7)$



## 0. Initial Setting


```{r warning = FALSE}
set.seed(0)
n <- 400
m <- 10
p <- 30
b <- 15
num_rank <- 5
num_rank_X <- 10
simul_times <- 100

sigma_mat <- matrix(nrow = num_rank_X, ncol = num_rank_X)
for(j in 1:num_rank_X) {
  for(k in 1:num_rank_X) {
    sigma_mat[j, k] <- 0.3^(abs(j-k))
  }
}

X_list <- list()
LR_mat_list <- list()
sp_mat_list <- list()
eps_list <- list()

for(simul in 1:simul_times) {
  X <- matrix(rnorm(n*num_rank_X, mean = 0, sd = 1), nrow = n)
  X <- X %*% expm::sqrtm(sigma_mat)
  X <- cbind(X, X, X)
  for(j in 11:20) {
    X[, j] <- X[, j-10] + X[, j-9]
    X[, (j+10)] <- X[, j-10] + X[, j-8]
  }
  X_list[[simul]] <- X %>% cbind(rep(1, n), .)
  
  col_ind <- sample(1:m, size = m, replace = FALSE)
  row_ind <- sample(1:(p+1), size = m)
  sp_mat_list[[simul]] <- matrix(0, nrow = p+1, ncol = m)
  for(i in 1:m) {
    sp_mat_list[[simul]][row_ind[i], col_ind[i]] <- rnorm(1, mean = 5, sd = 0.1)
  }
  
  LR_mat <- matrix(rnorm((p+1)*m, mean = 0, sd = 1), ncol = m) # make low rank matrix using SVD
  SVD <- svd(LR_mat)
  D_mat <- diag(runif(num_rank, min = 2, max = 2.3) %>% sort(decreasing = TRUE), nrow = length(SVD$d))
  idx <- (num_rank+1):min(m, p)
  D_mat[idx, idx] <- 0
  LR_mat_list[[simul]] <- SVD$u %*% D_mat %*% t(SVD$v)
  
  sigma <- runif(n*m,0.4, 0.7)
  eps_entry <- sapply(sigma, FUN = function(x) LaplacesDemon::rlaplace(1, location = 0, scale = x))
  eps_list[[simul]] <- matrix(eps_entry, nrow = n, ncol = m)
}

Y_list <- mapply(FUN = function(X, LR, SP, eps) X %*% (LR + SP) + eps, 
                 X_list, LR_mat_list, sp_mat_list, eps_list, SIMPLIFY = FALSE)


```

---

# 1. Basis Function.

```{r}
K <- 10
tau_seq <- seq(from = 0.35, to = 0.65, length.out = b)
tau_seq_real <- tau_seq[tau_seq >= 0.4 & tau_seq  <= 0.6]

knots_seq <- seq(min(tau_seq)- 0.02, max(tau_seq) + 0.02, length.out = K)
Phi <- fda::bsplineS(tau_seq, breaks= knots_seq, norder=2, nderiv=0, returnMatrix=FALSE)

V_list <- list()
for(simul in 1:simul_times) {
  V_list[[simul]] <- calc_V(X_list[[simul]], Phi)
}
```


# 2. Simulation

```{r}
start <- Sys.time()
cores=detectCores()
cl <- makeCluster(cores[1]-2) #not to overload your computer
registerDoParallel(cl) # Ready to parallel
simulation <- foreach(simul = 1:simul_times, .noexport = "add_decomp") %dopar% {
  library(tidyverse)
  library(splines)
  library(Matrix)
  library(Rcpp)
  library(glmnet)
  library(fda)
  sourceCpp("functions/add_decomp_function.cpp")
  
  tau_seq <- seq(from = 0.35, to = 0.65, length.out = b)
  lasso_coef <- matrix(nrow = p+1, ncol = m)
  X <- X_list[[simul]]
  Y <- Y_list[[simul]]
  V <- V_list[[simul]]
  for(g in 1:m) {
    cv.lasso <- cv.glmnet(x = X[, -1], y = Y[, g], 
                          alpha = 1, type.measure = "mae")
    lasso_model <- glmnet(X[, -1], Y[, g], 
                          family = "gaussian", alpha = 1, lambda = 0.01)
    lasso_coef[, g] <- c(lasso_model$a0, as.vector(lasso_model$beta))
  }
  
  theta_init <- matrix(nrow = (p+1)*K, ncol = m)
  for(g in 1:m) {
    for(j in 0:p) {
      theta_init[((j*K)+1):((j+1)*K), g] <- lasso_coef[j+1, g]
    }
  }
  
  Y_modified <- Y - X%*%lasso_coef
  ridge_coef <- matrix(nrow = p+1, ncol = m)
  for(g in 1:m) {
    cv.ridge <- cv.glmnet(x = X[, -1], y = Y_modified[, g], alpha = 0, type.measure = "mae")
    ridge_model <- glmnet(X[, -1], Y_modified[, g], family = "gaussian", alpha = 0, lambda = cv.ridge$lambda.min)
    ridge_coef[, g] <- c(ridge_model$a0, as.vector(ridge_model$beta))
    }
  alpha_init <- ridge_coef
  
  init_val <- add_decomp_r(delta = 1, lambda_1 = 0.01, lambda_2 = 0.2, tol_error = 0.1, max_iter = 50,
                           X = X, Y = Y, V = V, Phi = Phi, 
                           theta_0 = theta_init, Z_0 = X%*%alpha_init, tau_seq = tau_seq, weight = FALSE)
  
  lamb1_seq <- c( seq(0.08, 0.2, by = 0.01))
  lamb2_seq <- c(seq(0.5, 2, by = 0.1))
  BIC_simul <- BIC_func(X, Y, V, Phi, theta_0 = init_val$theta, Z_0 = init_val$Z, tau_seq, tau_seq_real, 
                        lamb1_seq = lamb1_seq, lamb2_seq = lamb2_seq, max_iter = 50)
  
  BIC_params <- BIC_simul$min_BIC %>%
    arrange(BIC_log_p) %>%
    head(1)
  
  result <- BIC_simul$simulation[[which(lamb1_seq == BIC_params$lambda_1)]][[which(lamb2_seq == BIC_params$lambda_2)]]
  
  result
  
}
stopCluster(cl)
end <- Sys.time()
```



```{r}
for(simul in 1:(cores[1]-2)) {
  tau_seq <- seq(from = 0.35, to = 0.65, length.out = b)
  lasso_coef <- matrix(nrow = p+1, ncol = m)
  X <- X_list[[simul]]
  Y <- Y_list[[simul]]
  V <- V_list[[simul]]
  for(g in 1:m) {
    cv.lasso <- cv.glmnet(x = X[, -1], y = Y[, g], 
                          alpha = 1, type.measure = "mae")
    lasso_model <- glmnet(X[, -1], Y[, g], 
                          family = "gaussian", alpha = 1, lambda = cv.lasso$lambda.min)
    lasso_coef[, g] <- c(lasso_model$a0, as.vector(lasso_model$beta))
  }
  
  theta_init <- matrix(nrow = (p+1)*K, ncol = m)
  for(g in 1:m) {
    for(j in 0:p) {
      theta_init[((j*K)+1):((j+1)*K), g] <- lasso_coef[j+1, g]
    }
  }
  
  Y_modified <- Y - X%*%lasso_coef
  lin_model <- lm(Y_modified~., data = data.frame(X[, -1]))
  alpha_init <- lin_model$coefficients

  result <- add_decomp(delta = 1, lambda_1 = 8, lambda_2 = 40, tol_error = 0.1, max_iter = 300,
                       X = X, Y = Y, V = V, Phi = Phi, 
                     theta_0 = theta_init, alpha_0 = alpha_init, tau_seq = tau_seq)
  simulation[[simul]] <- result
}
```


# 3. Evaluation.


## 3-1. Low rank matrix

```{r}
Z_list <- lapply(simulation, FUN = function(x) x$Z)

sapply(Z_list, rankMatrix) %>% mean
```

```{r}
lapply(Z_list, FUN= function(x) svd(x) %>% .$d) %>%
  sapply(FUN = function(x) sum(x[1:5])/sum(x)) %>% mean
```

## 3-2. Sparse matrix

```{r}
theta_list <- lapply(simulation, FUN = function(x) x$theta)

idx_tau <- (tau_seq >= 0.4 & tau_seq <= 0.6)
gamma_list <- lapply(theta_list, FUN = function(x) est_gamma(Phi[idx_tau, ], theta = x))
```


```{r message=FALSE}
sp_table <- list()
for(simul in 1:simul_times) {
  sp_table[[simul]] <- check_sp_table(true = sp_mat_list[[simul]], est = gamma_list[[simul]], 
                                      table = FALSE, tau_seq = tau_seq_real)
}


sp_table %>%
  bind_rows() %>%
  mutate(TP = TPR, TN = 1-FPR) %>%
  dplyr::select(TP, TN) %>%
  summarise(TP_mean = mean(TP), TP_sd = sd(TP), TN_mean = mean(TN), TN_sd = sd(TN))

```


## 3-3. Estimation Error


$$\begin{aligned}EE &= \sqrt{\int_\Delta\sum_{j=1}^p\sum_{g=1}^m\bigg(\hat{\Gamma}(\tau_\ell)-\Gamma(\tau_\ell)\bigg)^2d\tau/p},\text{   where }\tau_\ell\in[0.4,0.6]\\&=\sqrt{\sum_{g=1}^m\sum_{j=1}^p\int_\Delta\bigg(\hat{\Gamma}(\tau_\ell)-\Gamma(\tau_\ell)\bigg)^2d\tau/p}\end{aligned}$$


```{r}
h <- tau_seq_real[2] - tau_seq_real[1]

EE <- vector(mode = "numeric", length = simul_times)
for(simul in 1:simul_times) {
  sp_mat <- sp_mat_list[[simul]]
  EE_mat <- lapply(gamma_list[[simul]][-1], FUN = function(x) (x - sp_mat)*(x-sp_mat) * h) %>%
    Reduce("+", .)
  EE[simul] <- EE_mat %>% apply(2, mean) %>% sum %>% sqrt
}

c(mean(EE), sd(EE))
```




# Solution Path

## 1. Data Generation

```{r}
set.seed(0)
n <- 400
m <- 10
p <- 30
#num_nz <- 15   #round((p+1)*m*(1/5)) 
b <- 15
num_rank <- 5

X <- matrix(rnorm(n*p, mean = 0, sd = 1), nrow = n) %>% cbind(1, .)   #add intercept term in X

#sp_mat <- rsparsematrix(nrow = p+1, ncol = m, nnz = num_nz)             # make sparse matrix
#for(i in 1:(p+1)) {
  #for(j in 1:m) {
    #if(abs(sp_mat[i, j]) != 0) {sp_mat[i, j] <- rnorm(1, mean = 5, sd = 0.1)}
  #}
#}
col_ind <- sample(1:m, size = m, replace = FALSE)
row_ind <- sample(1:(p+1), size = m)
sp_mat <- matrix(0, nrow = p+1, ncol = m)
for(i in 1:m) {
  sp_mat[row_ind[i], col_ind[i]] <- rnorm(1, mean = 5, sd = 0.1)
}
num_zero <- which(sp_mat==0, arr.ind = TRUE) %>% nrow
num_nz <- (p+1)*m - num_zero

LR_mat <- matrix(rnorm((p+1)*m, mean = 1, sd = 0.1), ncol = m) # make low rank matrix using SVD
SVD <- svd(LR_mat)
D_mat <- diag(SVD$d)
idx <- (num_rank+1):m
D_mat[idx, idx] <- 0
LR_mat <- SVD$u %*% D_mat %*% t(SVD$v)          

true_B <- sp_mat + LR_mat            # B(tau) = sparse matrix + low rank matrix

eps <- matrix(rnorm(n*m, mean = 0, sd = 0.1), nrow = n)

Y <- X%*%true_B + eps
```


```{r}
K <- 10
tau_seq <- seq(from = 0.35, to = 0.65, length.out = b)
tau_seq_real <- tau_seq[tau_seq > 0.39 & tau_seq < 0.61]

knots_seq <- seq(min(tau_seq)- 0.02, max(tau_seq) + 0.02, length.out = K)
Phi <- fda::bsplineS(tau_seq, breaks= knots_seq, norder=2, nderiv=0, returnMatrix=FALSE)

V <- calc_V(X, Phi)
```

## 2. Low rank

```{r}
cores=detectCores()
cl <- makeCluster(cores[1]-2) #not to overload your computer
registerDoParallel(cl) # Ready to parallel
lamb1_seq <- seq(0.000001, 0.0005, 0.000005)

simulation <- foreach(lambda_1 = lamb1_seq, .noexport = "add_decomp") %dopar% {
  library(tidyverse)
  library(splines)
  library(Matrix)
  library(Rcpp)
  library(glmnet)
  library(fda)
  sourceCpp("functions/add_decomp_function.cpp")
  
  tau_seq <- seq(from = 0.35, to = 0.65, length.out = b)
  lasso_coef <- matrix(nrow = p+1, ncol = m)
  for(g in 1:m) {
    cv.lasso <- cv.glmnet(x = X[, -1], y = Y[, g], 
                          alpha = 1, type.measure = "mae")
    lasso_model <- glmnet(X[, -1], Y[, g], 
                          family = "gaussian", alpha = 1, lambda = cv.lasso$lambda.min)
    lasso_coef[, g] <- c(lasso_model$a0, as.vector(lasso_model$beta))
  }
  
  theta_init <- matrix(nrow = (p+1)*K, ncol = m)
  for(g in 1:m) {
    for(j in 0:p) {
      theta_init[((j*K)+1):((j+1)*K), g] <- lasso_coef[j+1, g]
    }
  }
  
  Y_modified <- Y - X%*%lasso_coef
  lin_model <- lm(Y_modified~., data = data.frame(X[, -1]))
  alpha_init <- lin_model$coefficients
  
  result <- add_decomp(delta = 1, lambda_1 = lambda_1, lambda_2 = 200, tol_error = 0.1,max_iter = 50,
                       X = X, Y = Y, V = V, Phi = Phi, 
                     theta_0 = theta_init, alpha_0 = alpha_init, tau_seq = tau_seq)
  result
}



stopCluster(cl)
```


```{r}
for(i in 1:(cores[1]-2)) {
  tau_seq <- seq(from = 0.35, to = 0.65, length.out = b)
  lasso_coef <- matrix(nrow = p+1, ncol = m)
  
  for(g in 1:m) {
    cv.lasso <- cv.glmnet(x = X[, -1], y = Y[, g], 
                          alpha = 1, type.measure = "mae")
    lasso_model <- glmnet(X[, -1], Y[, g], 
                          family = "gaussian", alpha = 1, lambda = cv.lasso$lambda.min)
    lasso_coef[, g] <- c(lasso_model$a0, as.vector(lasso_model$beta))
  }
  
  theta_init <- matrix(nrow = (p+1)*K, ncol = m)
  for(g in 1:m) {
    for(j in 0:p) {
      theta_init[((j*K)+1):((j+1)*K), g] <- lasso_coef[j+1, g]
    }
  }
  
  Y_modified <- Y - X%*%lasso_coef
  lin_model <- lm(Y_modified~., data = data.frame(X[, -1]))
  alpha_init <- lin_model$coefficients
  result <- add_decomp(delta = 1, lambda_1 = lamb1_seq[i], lambda_2 = 40, tol_error = 0.1, max_iter = 300,
                       X = X, Y = Y, V = V, Phi = Phi, 
                     theta_0 = theta_init, alpha_0 = alpha_init, tau_seq = tau_seq)
  simulation[[i]] <- result
}
```


```{r}
rank <- simulation %>% sapply(FUN = function(x) x$alpha %>% rankMatrix %>% .[1])

data.frame(lambda_1 = lamb1_seq, rank = rank) %>%
  ggplot() +
  geom_line(aes(x = lambda_1, y = rank)) +
  labs(title = "Solution path for low rank matrix", 
       x = expression(lambda[1])) +
  expand_limits(y = c(0, 10))
```

$$\begin{aligned}\text{Integrate }\Gamma(\tau) &= \sqrt{\int_\Delta \Gamma(\tau)^2 d\tau}\quad\text{          where }\tau_\ell\in[0.4, 0.6]\\&=\sqrt{\sum_{\ell=1}^bh\times\Gamma^2(\tau_\ell)}\end{aligned}$$


```{r}
h <- tau_seq[2] - tau_seq[1]
theta_list <- lapply(simulation, FUN = function(x) x$theta)

idx_tau <- (tau_seq >= 0.4 & tau_seq <= 0.6)
gamma_list <- lapply(theta_list, FUN = function(x) est_gamma(Phi[idx_tau, ], theta = x))

ex <- gamma_list[[1]]
nz_idx_true <- which(abs(sp_mat) > 0.1^5, arr.ind = TRUE) %>% as_tibble
nz_idx_est <- lapply(ex, FUN = function(x) which(abs(x) > 0.1^5, arr.ind = TRUE) %>% as_tibble) %>%
    bind_rows (.id = "tau") %>%
    group_by(row, col) %>%
    summarise(count = n()) %>%
  mutate(nonzero = ifelse(count == length(tau_seq_real), "all", "partial"))

nz_est_list <- list()
for(i in 1:length(lamb1_seq)) {
  gamma_hat_tau <- gamma_list[[i]]
  nz_est_list[[i]] <- lapply(gamma_hat_tau, 
                             FUN = function(x) which(abs(x) > 0.1^5, arr.ind = TRUE) %>% as_tibble) %>%
    bind_rows (.id = "tau") %>%
    group_by(row, col) %>%
    summarise(count = n())
}

nz_est_list %>% `names<-`(value = lamb1_seq) %>%
  bind_rows(.id = "lambda_1") %>%
  mutate(index = paste0("(", row, ",", col, ")"), 
         lambda_1 = as.numeric(lambda_1)) %>%
  ungroup() %>%
  select(-row, -col) %>%
  spread(key = index, value = count)

```



## 3. Sparse matrix

```{r}
cores=detectCores()
cl <- makeCluster(cores[1]-2) #not to overload your computer
registerDoParallel(cl) # Ready to parallel
lamb2_seq <- seq(300, 20000, by = 200)

simulation <- foreach(lambda_2 = lamb2_seq, .noexport = "add_decomp") %dopar% {
  library(tidyverse)
  library(splines)
  library(Matrix)
  library(Rcpp)
  library(glmnet)
  library(fda)
  sourceCpp("functions/add_decomp_function.cpp")
  
  tau_seq <- seq(from = 0.35, to = 0.65, length.out = b)
  lasso_coef <- matrix(nrow = p+1, ncol = m)
  for(g in 1:m) {
    cv.lasso <- cv.glmnet(x = X[, -1], y = Y[, g], 
                          alpha = 1, type.measure = "mae")
    lasso_model <- glmnet(X[, -1], Y[, g], 
                          family = "gaussian", alpha = 1, lambda = cv.lasso$lambda.min)
    lasso_coef[, g] <- c(lasso_model$a0, as.vector(lasso_model$beta))
  }
  
  theta_init <- matrix(nrow = (p+1)*K, ncol = m)
  for(g in 1:m) {
    for(j in 0:p) {
      theta_init[((j*K)+1):((j+1)*K), g] <- lasso_coef[j+1, g]
    }
  }
  
  Y_modified <- Y - X%*%lasso_coef
  lin_model <- lm(Y_modified~., data = data.frame(X[, -1]))
  alpha_init <- lin_model$coefficients
  
  result <- add_decomp(delta = 1, lambda_1 = 0.000011, lambda_2 = lambda_2, 
                       tol_error = 0.1,max_iter = 50,
                       X = X, Y = Y, V = V, Phi = Phi, 
                     theta_0 = theta_init, alpha_0 = alpha_init, tau_seq = tau_seq)
  result
}



stopCluster(cl)
```

```{r}
for(i in 1:(cores[1]-2)) {
  tau_seq <- seq(from = 0.35, to = 0.65, length.out = b)
  lasso_coef <- matrix(nrow = p+1, ncol = m)
  
  for(g in 1:m) {
    cv.lasso <- cv.glmnet(x = X[, -1], y = Y[, g], 
                          alpha = 1, type.measure = "mae")
    lasso_model <- glmnet(X[, -1], Y[, g], 
                          family = "gaussian", alpha = 1, lambda = cv.lasso$lambda.min)
    lasso_coef[, g] <- c(lasso_model$a0, as.vector(lasso_model$beta))
  }
  
  theta_init <- matrix(nrow = (p+1)*K, ncol = m)
  for(g in 1:m) {
    for(j in 0:p) {
      theta_init[((j*K)+1):((j+1)*K), g] <- lasso_coef[j+1, g]
    }
  }
  
  Y_modified <- Y - X%*%lasso_coef
  lin_model <- lm(Y_modified~., data = data.frame(X[, -1]))
  alpha_init <- lin_model$coefficients
  result <- add_decomp(delta = 1, lambda_1 = 4, lambda_2 = lamb2_seq[i], tol_error = 0.1, max_iter = 300,
                       X = X, Y = Y, V = V, Phi = Phi, 
                     theta_0 = theta_init, alpha_0 = alpha_init, tau_seq = tau_seq)
  simulation[[i]] <- result
}
```



$$\int_\Delta\{\hat{\Gamma}(\tau)\}_{jg}d\tau=\sum_{\ell=1}^b\{\hat{\Gamma}(\tau)\}_{jg}\frac{\Delta}{(b-1)}$$

```{r}
h <- tau_seq[2] - tau_seq[1]
alpha_list <- lapply(simulation, FUN = function(x) x$alpha)
theta_list <- lapply(simulation, FUN = function(x) x$theta)

idx_tau <- (tau_seq > 0.39 & tau_seq <= 0.61)
gamma_list <- lapply(theta_list, FUN = function(x) est_gamma(Phi[idx_tau, ], theta = x))

gamma_square <- gamma_list %>% lapply(FUN = function(x) lapply(x[-1], FUN = function(x) x * x))
sum_gamma_list <- lapply(gamma_square, FUN = function(x) x %>% Reduce("+", .))  #summation per lambda 2

int_gamma <- sum_gamma_list %>% lapply(FUN = function(x) x*h)

int_gamma_tidy <- lapply(int_gamma, FUN = function(x) data.frame(col = rep(1:m, each = (p+1)), 
                                                          row = rep(1:(p+1), m),
                                                          value = as.vector(x))) %>%
  `names<-`(value = lamb2_seq) %>%
  bind_rows(.id = "lambda_2") %>% tbl_df %>%
  mutate(lambda_2 = as.numeric(lambda_2), row = as.character(row), value = sqrt(value))

int_gamma_tidy %>%
  mutate(index = paste0("(", col, ",", row, ")")) %>%
  ggplot() +
  geom_line(aes(x = lambda_2, y = value, group = index)) +
  labs(title = "Solution path for sparse matrix", 
       x = expression(lambda[2]), 
       y = expression("integrate"~Gamma~"("~tau~")"))
```















